{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae5a1d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7241/4258669431.py:47: RuntimeWarning: you're running with a custom agents_mask\n",
      "  test_dataset = EgoAgentDatasetVectorized(cfg, test_zarr, vectorizer, agents_mask=test_mask, eval_mode=True)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "\n",
    "from l5kit.configs import load_config_data\n",
    "from l5kit.data import ChunkedDataset, LocalDataManager\n",
    "from l5kit.dataset import EgoAgentDatasetVectorized, AgentDataset, EgoDatasetVectorized\n",
    "from l5kit.evaluation import write_pred_csv, compute_metrics_csv, read_gt_csv, create_chopped_dataset\n",
    "from l5kit.evaluation.chop_dataset import MIN_FUTURE_STEPS\n",
    "from l5kit.evaluation.metrics import average_displacement_error_oracle, final_displacement_error_oracle\n",
    "from l5kit.planning.vectorized.common import build_matrix, transform_points\n",
    "from l5kit.prediction.vectorized.safepathnet_model import SafePathNetModel\n",
    "from l5kit.vectorization.vectorizer_builder import build_vectorizer\n",
    "from l5kit.rasterization import build_rasterizer\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "from tempfile import gettempdir\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import functional as F\n",
    "from tqdm import tqdm\n",
    "import math \n",
    "\n",
    "from utils import preprocess\n",
    "from config import GPTConfig\n",
    "\n",
    "torch.manual_seed(123)\n",
    "np.random.seed(123)\n",
    "\n",
    "os.environ[\"L5KIT_DATA_FOLDER\"] = \"/home/alexay/lyft-attn/DATASET_DIR/\"\n",
    "\n",
    "# define local data manager\n",
    "dm = LocalDataManager(None)\n",
    "\n",
    "# load the experiment config\n",
    "cfg = load_config_data(\"../solution/config.yaml\")\n",
    "print(\"Configuration loaded.\")\n",
    "\n",
    "# Load Test Dataset \n",
    "vectorizer = build_vectorizer(cfg, dm)\n",
    "test_zarr_path = os.path.join(os.environ[\"L5KIT_DATA_FOLDER\"], \"scenes/test.zarr\")\n",
    "test_zarr = ChunkedDataset(test_zarr_path).open()\n",
    "test_mask = np.load(f\"{cfg['dataset_path']}/scenes/mask.npz\")[\"arr_0\"]\n",
    "test_dataset = EgoAgentDatasetVectorized(cfg, test_zarr, vectorizer, agents_mask=test_mask, eval_mode=True)\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a6261ba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 50, 1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[0]['all_other_agents_future_yaws'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ea97f7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EVAL LOOP\n",
    "from new_models import NewTFModel, TransformerTrajectoryPredictor\n",
    "from loss_func import mse_loss\n",
    "import torch \n",
    "\n",
    "#model = NewTFModel()\n",
    "model = TransformerTrajectoryPredictor(hidden_dim=32, num_transformer_layers=1) \n",
    "\n",
    "model.eval()\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "device = 'cpu'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bd454210",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/708 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 708/708 [13:40<00:00,  1.16s/it]\n"
     ]
    }
   ],
   "source": [
    "# store information for evaluation\n",
    "future_coords_offsets_pd = []\n",
    "future_traj_confidence = []\n",
    "timestamps = []\n",
    "agent_ids = []\n",
    "agent_of_interest_ids = []\n",
    "missing_agent_of_interest_ids = []\n",
    "missing_agent_of_interest_timestamp = []\n",
    "\n",
    "# torch.isin is available only form pytorch 1.10 - defining a simple alternative\n",
    "def torch_isin(ar1, ar2):\n",
    "    return (ar1[..., None] == ar2).any(-1)\n",
    "\n",
    "# iterate over validation dataset\n",
    "#progress_bar = tqdm(eval_dataloader)\n",
    "progress_bar = tqdm(test_dataloader)\n",
    "for data in progress_bar:\n",
    "    data = {k: v.to(device) for k, v in data.items()}\n",
    "    outputs = model(data['all_other_agents_history_positions']) \n",
    "\n",
    "    # [batch_size, max_num_agents, num_trajectories, num_timesteps, 2]\n",
    "    agent_xy = outputs.unsqueeze(2) #bs, agents, traj, timesteps, 2\n",
    "    # [batch_size, max_num_agents, num_trajectories, num_timesteps, 1]\n",
    "    agent_yaw = data[\"all_other_agents_future_yaws\"].unsqueeze(2)\n",
    "    # [batch_size, max_num_agents, num_trajectories]\n",
    "    agent_logits = torch.ones((outputs.shape[0], 50, 1)) # to be generated from model\n",
    "\n",
    "    # [batch_size, max_num_agents, num_trajectories, num_timesteps, 3]\n",
    "    agent_pos = torch.cat((agent_xy, agent_yaw), dim=-1)\n",
    "\n",
    "    # ego-centric agent coords must be converted to world frame first\n",
    "    # [batch_size, 3, 3]\n",
    "    world_from_agents = data[\"world_from_agent\"].float()\n",
    "    # [batch_size]\n",
    "    world_from_agents_yaw = data[\"yaw\"].float()\n",
    "    # shape of data[\"all_other_agents_history_positions\"]: [batch_size, num_agents, num_history_frames, 2]\n",
    "    # [batch_size, num_agents, 1, 3]\n",
    "    agent_t0_pos_yaw = torch.cat((data[\"all_other_agents_history_positions\"][:, :, :1],\n",
    "                                  data[\"all_other_agents_history_yaws\"][:, :, :1]), dim=-1)\n",
    "    agent_t0_avail = data[\"all_other_agents_history_availability\"][:, :, :1]\n",
    "    # [batch_size, num_agents, 1, 3]\n",
    "    world_agent_t0_pos_yaw = transform_points(agent_t0_pos_yaw, world_from_agents, avail=agent_t0_avail,\n",
    "                                              yaw=world_from_agents_yaw)\n",
    "    world_agent_pos = transform_points(agent_pos.flatten(2,3), world_from_agents, avail=agent_t0_avail).view_as(agent_pos)\n",
    "\n",
    "    # then can be converted to agent-relative\n",
    "    world_agents_t0_pos_exp = world_agent_t0_pos_yaw[..., :2]\n",
    "    world_agents_t0_yaw_exp = world_agent_t0_pos_yaw[..., 2]\n",
    "    # [batch_size * max_num_agents, 3, 3]\n",
    "    _, matrix = build_matrix(world_agents_t0_pos_exp.reshape(-1, 2), world_agents_t0_yaw_exp.reshape(-1))\n",
    "    # [batch_size, max_num_agents, 3, 3]\n",
    "    matrix = matrix.view(list(world_agent_t0_pos_yaw.shape[:2]) + [3, 3])\n",
    "    # [batch_size * max_num_agents * num_trajectories * num_timesteps, 3, 3]\n",
    "    matrix = matrix.unsqueeze(2).unsqueeze(2).expand(list(agent_pos.shape[:-1]) + [3, 3]).reshape(-1, 3, 3)\n",
    "    coords_offset = transform_points(world_agent_pos.reshape(-1, 1, 1, 3), matrix,\n",
    "                                     avail=torch.ones_like(world_agent_pos.reshape(-1, 1, 1, 3)[..., 0]))\n",
    "    coords_offset = coords_offset.view_as(world_agent_pos)\n",
    "\n",
    "    # need to filter per agents of interest (from original prediction evaluation)\n",
    "    agents_track_ids = data[\"all_other_agents_track_ids\"]\n",
    "    agents_of_interest = data[\"all_valid_agents_track_ids\"]\n",
    "    agents_track_ids_mask = torch.zeros_like(agents_track_ids, dtype=torch.bool)\n",
    "    missing_agents_mask = torch.zeros_like(agents_of_interest, dtype=torch.bool)\n",
    "    for batch_idx in range(agents_track_ids.shape[0]):\n",
    "        agents_track_ids_mask[batch_idx] = torch_isin(agents_track_ids[batch_idx], agents_of_interest[batch_idx]) * \\\n",
    "                                           agents_track_ids[batch_idx] != 0\n",
    "        missing_agents_mask[batch_idx] = ~torch_isin(agents_of_interest[batch_idx], agents_track_ids[batch_idx]) * \\\n",
    "                                         agents_of_interest[batch_idx] != 0\n",
    "    # we may miss some agents due to the limit cfg[\"data_generation_params\"][\"other_agents_num\"], we will consider them stationary\n",
    "    missing_agents_ids = agents_of_interest[missing_agents_mask]\n",
    "    if torch.any(missing_agents_mask):\n",
    "        # print(len(missing_agents_ids), missing_agents_ids[missing_agents_ids != 0])\n",
    "        missing_agents_ids = missing_agents_ids[missing_agents_ids != 0]\n",
    "        missing_agent_of_interest_ids.append(missing_agents_ids.cpu())\n",
    "        missing_timestamps = []\n",
    "        for batch_idx, num_missing_agents in enumerate(missing_agents_mask.sum(-1)):\n",
    "            missing_timestamps.extend([data[\"timestamp\"][batch_idx]] * num_missing_agents)\n",
    "        missing_agent_of_interest_timestamp.append(torch.tensor(missing_timestamps))\n",
    "\n",
    "    # move the valida data to CPU\n",
    "    relevant_coords_offset = coords_offset[agents_track_ids_mask].cpu()\n",
    "    traj_confidence = agent_logits[agents_track_ids_mask].cpu()\n",
    "    relevant_agent_track_ids = agents_track_ids[agents_track_ids_mask].cpu()\n",
    "    relevant_timestamps = data[\"timestamp\"].unsqueeze(1).expand(agents_track_ids.shape)[agents_track_ids_mask].cpu()\n",
    "\n",
    "    # add them to the result lists\n",
    "    future_coords_offsets_pd.append(relevant_coords_offset)\n",
    "    future_traj_confidence.append(traj_confidence)\n",
    "    timestamps.append(relevant_timestamps)\n",
    "    agent_ids.append(relevant_agent_track_ids)\n",
    "\n",
    "\n",
    "# add the missing agents as stationary\n",
    "missing_agent_of_interest_ids = torch.cat(missing_agent_of_interest_ids, dim=0)\n",
    "missing_agent_of_interest_timestamp = torch.cat(missing_agent_of_interest_timestamp, dim=0)\n",
    "stationary_trajectories = torch.zeros(list(missing_agent_of_interest_ids.shape[:1]) + list(future_coords_offsets_pd[0].shape[1:]))\n",
    "uniform_probabilities = torch.ones(list(missing_agent_of_interest_ids.shape[:1]) + list(future_traj_confidence[0].shape[1:]))\n",
    "agent_ids.append(missing_agent_of_interest_ids)\n",
    "future_coords_offsets_pd.append(stationary_trajectories)\n",
    "future_traj_confidence.append(uniform_probabilities)\n",
    "timestamps.append(missing_agent_of_interest_timestamp)\n",
    "\n",
    "# concatenate all the results in a single np array\n",
    "future_coords_offsets_pd = torch.cat(future_coords_offsets_pd, dim=0).numpy()\n",
    "future_traj_confidence = torch.cat(future_traj_confidence, dim=0).softmax(-1).numpy()\n",
    "timestamps = torch.cat(timestamps, dim=0).numpy().astype(np.int64)\n",
    "agent_ids = torch.cat(agent_ids, dim=0).numpy().astype(np.int64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "abf35180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall, we missed 70 agents over a total of 94694 agents (~0.00074%)\n"
     ]
    }
   ],
   "source": [
    "# let's verify the number of coordinates corresponds to the number of coordinates in the original\n",
    "assert len(future_coords_offsets_pd == 94694)\n",
    "\n",
    "print(f\"Overall, we missed {len(missing_agent_of_interest_ids)} agents over a total of {94694} agents \"\n",
    "      f\"(~{len(missing_agent_of_interest_ids)/94694:.5f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e5e667a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71122/71122 [00:07<00:00, 10030.51it/s]\n"
     ]
    }
   ],
   "source": [
    "pred_path = f\"{os.getcwd()}/new_test_pred.csv\"\n",
    "\n",
    "write_pred_csv(pred_path,\n",
    "               timestamps=timestamps,\n",
    "               track_ids=agent_ids,\n",
    "               coords=future_coords_offsets_pd[..., :2],\n",
    "               confs=future_traj_confidence,\n",
    "               max_modes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ca79e34e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71122, 1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "future_traj_confidence.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac632044",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f68170",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
